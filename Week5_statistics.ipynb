{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed69daed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "        Age      Fare  FamilySize  Sex_female  Sex_male  Embarked_C  \\\n",
      "0  1.253641 -0.078684   -0.554666         0.0       1.0         0.0   \n",
      "1 -0.477284 -0.377145   -0.554666         0.0       1.0         0.0   \n",
      "2  0.215086 -0.474867   -0.554666         0.0       1.0         0.0   \n",
      "3 -0.246494 -0.476230    0.040096         0.0       1.0         0.0   \n",
      "4 -1.785093 -0.025249    3.013909         1.0       0.0         0.0   \n",
      "\n",
      "   Embarked_Q  Embarked_S  \n",
      "0         0.0         1.0  \n",
      "1         0.0         1.0  \n",
      "2         0.0         1.0  \n",
      "3         0.0         1.0  \n",
      "4         0.0         1.0  \n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the dataset\n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Display first few rows of the dataset\n",
    "print(data.head())\n",
    "\n",
    "# Data Cleaning and Handling Missing Values\n",
    "# Drop columns that are not useful for prediction\n",
    "data.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin'], inplace=True)\n",
    "\n",
    "# Fill missing values\n",
    "# Fill 'Age' with the median value\n",
    "data['Age'].fillna(data['Age'].median(), inplace=True)\n",
    "\n",
    "# Fill 'Embarked' with the most common value\n",
    "data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# Drop rows where 'Fare' is missing (if any)\n",
    "data.dropna(subset=['Fare'], inplace=True)\n",
    "\n",
    "# Feature Engineering\n",
    "# Create new feature 'FamilySize' from 'SibSp' and 'Parch'\n",
    "data['FamilySize'] = data['SibSp'] + data['Parch'] + 1\n",
    "\n",
    "# Create new feature 'IsAlone' from 'FamilySize'\n",
    "data['IsAlone'] = np.where(data['FamilySize'] == 1, 1, 0)\n",
    "\n",
    "# Transforming categorical variables to numerical\n",
    "# Define categorical features to encode\n",
    "categorical_features = ['Sex', 'Embarked']\n",
    "\n",
    "# Define numerical features to scale\n",
    "numerical_features = ['Age', 'Fare', 'FamilySize']\n",
    "\n",
    "# Define preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(columns=['Survived'])\n",
    "y = data['Survived']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the preprocessing pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_preprocessed = pipeline.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data\n",
    "X_test_preprocessed = pipeline.transform(X_test)\n",
    "\n",
    "# Convert the preprocessed data back to a DataFrame\n",
    "preprocessed_columns = (\n",
    "    numerical_features +\n",
    "    list(pipeline.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(categorical_features))\n",
    ")\n",
    "X_train_preprocessed_df = pd.DataFrame(X_train_preprocessed, columns=preprocessed_columns)\n",
    "X_test_preprocessed_df = pd.DataFrame(X_test_preprocessed, columns=preprocessed_columns)\n",
    "\n",
    "# Display the first few rows of the preprocessed training data\n",
    "print(X_train_preprocessed_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41de5da0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
